{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "import seaborn as sns\n",
    "import time\n",
    "import re\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import OLS\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set styles\n",
    "sns.set_style('white')\n",
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_merged = pd.read_pickle(\"ADNIcsv/all_merged.pkl\")\n",
    "total_score_names = ['adas_total_0', 'adas_total_06', 'adas_total_12', \n",
    "                     'cdglobal_sc', 'cdglobal_06', 'cdglobal_12',  \n",
    "                     'faqtotal_bl', 'faqtotal_06', 'faqtotal_12', \n",
    "                     'gdtotal_sc', 'gdtotal_12',  \n",
    "                     'mmscore_sc', 'mmscore_06', 'mmscore_12', \n",
    "                     'hmscore',\n",
    "                     'npiscore_bl', 'npiscore_06', 'npiscore_12']\n",
    "hci_fields = ['hci_bl', 'hci_m06', 'hci_m12']\n",
    "total_scores = all_merged.loc[:, total_score_names + hci_fields]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.40918137  0.1717127   0.1198882   0.49760678  0.2856557 ]\n",
      "0.488407988516\n",
      "0.429232383372\n"
     ]
    }
   ],
   "source": [
    "# Baseline model using total scores from each exam\n",
    "# Use baseline and pre-screening predictors only; predict baseline HCI\n",
    "X_cols = [x for x in total_score_names if re.search(r'0|bl|sc', x) != None and re.search(r'hci',x) == None]\n",
    "# only keep observations that have all total scores and a baseline HCI measurement\n",
    "temp = total_scores[X_cols + ['hci_bl']].dropna()\n",
    "X = temp[X_cols]\n",
    "y = temp['hci_bl']\n",
    "\n",
    "# Split into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
    "\n",
    "baseline = LinearRegression()\n",
    "print(cross_val_score(baseline, X_train, y_train, cv=5, n_jobs=-1))\n",
    "baseline.fit(X_train, y_train)\n",
    "\n",
    "print(metrics.r2_score(y_train, baseline.predict(X_train)))\n",
    "print(metrics.r2_score(y_test, baseline.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.23354186  0.17460298  0.72799779  0.13840559  0.27949847]\n",
      "0.527257354732\n",
      "0.2994252453\n"
     ]
    }
   ],
   "source": [
    "# OLS using ADAS subscores\n",
    "adas_cols = [x for x in all_merged.columns if re.search(r'hci|cd|faq|gd|mm|RID|hm|npi|06|12|total', x) == None]\n",
    "adas_temp = all_merged[adas_cols + ['hci_bl']].dropna()\n",
    "X_adas = adas_temp[adas_cols]\n",
    "y_adas = adas_temp['hci_bl']\n",
    "\n",
    "# Split into training and test\n",
    "X_train_adas, X_test_adas, y_train_adas, y_test_adas = train_test_split(X_adas, y_adas, test_size=.2)\n",
    "\n",
    "baseline = LinearRegression()\n",
    "print(cross_val_score(baseline, X_train_adas, y_train_adas, cv=5, n_jobs=-1))\n",
    "baseline.fit(X_train_adas, y_train_adas)\n",
    "print(metrics.r2_score(y_train_adas, baseline.predict(X_train_adas)))\n",
    "print(metrics.r2_score(y_test_adas, baseline.predict(X_test_adas)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_on_exam(model, exam_prefix):\n",
    "    exam_cols = [x for x in all_merged.columns if re.search(r'hci|RID|06|12|total|global|score', x) == None and re.search(f'{exam_prefix}', x) != None]\n",
    "    exam_temp = all_merged[exam_cols + ['hci_bl']].dropna()\n",
    "    X_exam = exam_temp[exam_cols]\n",
    "    y_exam = exam_temp['hci_bl']\n",
    "    \n",
    "    # Split into training and test\n",
    "    X_train_exam, X_test_exam, y_train_exam, y_test_exam = train_test_split(X_exam, y_exam, test_size=.2)\n",
    "    \n",
    "    model = model()\n",
    "    print(cross_val_score(model, X_train_exam, y_train_exam, cv=5, n_jobs=-1))\n",
    "    print('Number of items: ', X_train_exam.shape[1])\n",
    "    model.fit(X_train_exam, y_train_exam)\n",
    "    train_score = metrics.r2_score(y_train_exam, model.predict(X_train_exam))\n",
    "    test_score = metrics.r2_score(y_test_exam, model.predict(X_test_exam))\n",
    "    return train_score, test_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03729281 -0.01943956  0.33033794 -0.0287696  -0.17177546]\n",
      "Number of items:  13\n",
      "(0.21009420475508045, 0.079031324135709125)\n",
      "\n",
      "\n",
      "[ 0.01973059 -0.46552873  0.14002071 -0.04382561 -0.01463751]\n",
      "Number of items:  13\n",
      "(0.16492048471070864, 0.16565190703653376)\n",
      "\n",
      "\n",
      "[-0.19703708  0.0903938   0.00208488 -0.08109694  0.16381247]\n",
      "Number of items:  13\n",
      "(0.16075682678578285, 0.15936683966012133)\n",
      "\n",
      "\n",
      "[ 0.15832311 -0.01943761  0.16012343 -0.47504338  0.20548312]\n",
      "Number of items:  13\n",
      "(0.22665088032836089, 0.013223451147024501)\n",
      "\n",
      "\n",
      "[-0.03704874 -0.18364146 -0.00984692 -0.15251972 -0.09160641]\n",
      "Number of items:  13\n",
      "(0.17528472710256526, 0.17065651050226616)\n",
      "\n",
      "\n",
      "[-0.66386138 -0.01177791  0.08235142 -0.1833735   0.09841256]\n",
      "Number of items:  13\n",
      "(0.18799864474222283, 0.014947148188055426)\n",
      "\n",
      "\n",
      "[-0.08763533 -0.32778175  0.06726909  0.0649801   0.21553317]\n",
      "Number of items:  13\n",
      "(0.19277384784097262, 0.042878743845860323)\n",
      "\n",
      "\n",
      "[ 0.25518355  0.04532645  0.07567336  0.06626183 -0.42231124]\n",
      "Number of items:  13\n",
      "(0.21894168426986815, -0.079797576454879726)\n",
      "\n",
      "\n",
      "[-0.08601555 -0.22581929  0.16932434  0.06738606 -0.11075164]\n",
      "Number of items:  13\n",
      "(0.18713366258685682, 0.15054852613515812)\n",
      "\n",
      "\n",
      "[-0.10977865 -0.12845382  0.08461125 -0.02142047 -0.07976568]\n",
      "Number of items:  13\n",
      "(0.17258475762488834, 0.16490896305574976)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(baseline_on_exam(LinearRegression, 'npi'))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word_recall_0',\n",
       " 'construction_0',\n",
       " 'delayed_word_recall_0',\n",
       " 'naming_0',\n",
       " 'ideational_praxis_0',\n",
       " 'orientation_0',\n",
       " 'word_recognition_0',\n",
       " 'recall_instructions_0',\n",
       " 'spoken_language_0',\n",
       " 'word_finding_0',\n",
       " 'comprehension_0',\n",
       " 'number_cancellation_0',\n",
       " 'adas_total_0']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adas_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Build model with significant items from each exam\n",
    "2. Stepforward selection\n",
    "3. PCA\n",
    "4. Random forest with limited depth (CV for depth and for p)\n",
    "5. AdaBoost\n",
    "\n",
    "Notebook\n",
    "1. Cleaning\n",
    "2. EDA\n",
    "3. Models\n",
    "\n",
    "Things to do\n",
    "1. Check that all the items are binary\n",
    "2. Figure out how to make the website\n",
    "3. PCA\n",
    "4. Random Forest\n",
    "5. Make nice looking version of cleaning notebook \n",
    "6. Make nice version of baseline models\n",
    "\n",
    "Send parts by Monday night. Meet Wednesday at 5:15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
